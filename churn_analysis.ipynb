{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ“Š Customer Churn Risk Modeling\n",
    "\n",
    "## Project Overview\n",
    "This notebook contains the complete analysis for predicting customer churn for a telecommunications company.\n",
    "\n",
    "**Business Goal**: Predict which customers are likely to leave (churn) so the company can take proactive retention actions.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Data Collection and Understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ML libraries\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score, \n",
    "                             f1_score, roc_auc_score, confusion_matrix,\n",
    "                             classification_report, roc_curve)\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "\n",
    "print('âœ… All libraries imported successfully!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('WA_Fn-UseC_-Telco-Customer-Churn.csv')\n",
    "print(f'âœ… Dataset loaded: {df.shape[0]:,} customers, {df.shape[1]} columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick look at the data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target variable distribution\n",
    "print('ğŸ“Š Churn Distribution:')\n",
    "print(df['Churn'].value_counts())\n",
    "print(f'\\nChurn Rate: {(df[\"Churn\"] == \"Yes\").mean() * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 2: Data Cleaning and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop customerID\n",
    "df = df.drop('customerID', axis=1)\n",
    "\n",
    "# Fix TotalCharges\n",
    "df['TotalCharges'] = pd.to_numeric(df['TotalCharges'], errors='coerce')\n",
    "\n",
    "# Drop rows with missing values\n",
    "df = df.dropna()\n",
    "\n",
    "print(f'âœ… Data cleaned: {len(df):,} customers, {df.shape[1]} features')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 3: Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution plots\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "axes[0].hist(df['tenure'], bins=30, color='steelblue', edgecolor='white')\n",
    "axes[0].set_title('Tenure Distribution', fontweight='bold')\n",
    "axes[0].set_xlabel('Tenure (months)')\n",
    "\n",
    "axes[1].hist(df['MonthlyCharges'], bins=30, color='coral', edgecolor='white')\n",
    "axes[1].set_title('Monthly Charges Distribution', fontweight='bold')\n",
    "axes[1].set_xlabel('Monthly Charges ($)')\n",
    "\n",
    "axes[2].hist(df['TotalCharges'], bins=30, color='seagreen', edgecolor='white')\n",
    "axes[2].set_title('Total Charges Distribution', fontweight='bold')\n",
    "axes[2].set_xlabel('Total Charges ($)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Churn by Contract Type\n",
    "churn_rate_contract = df.groupby('Contract')['Churn'].apply(lambda x: (x == 'Yes').mean() * 100)\n",
    "print('ğŸ“Š Churn Rate by Contract Type:')\n",
    "print(churn_rate_contract.sort_values(ascending=False))\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "churn_rate_contract.plot(kind='bar', color=['#e74c3c', '#f39c12', '#2ecc71'])\n",
    "plt.title('Churn Rate by Contract Type', fontweight='bold')\n",
    "plt.xlabel('Contract Type')\n",
    "plt.ylabel('Churn Rate (%)')\n",
    "plt.xticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print('\\nğŸ’¡ Month-to-month contracts have the highest churn!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 4: Class Imbalance Handling\n",
    "\n",
    "**The Problem**: We have ~73% non-churners vs ~27% churners. This is imbalanced.\n",
    "\n",
    "**Why it's a problem**: A model could just predict \"No churn\" for everyone and be 73% accurate, but useless.\n",
    "\n",
    "**Solution**: We'll use **SMOTE** (Synthetic Minority Oversampling Technique) to create synthetic samples of the minority class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, prepare data for modeling\n",
    "# Encode categorical variables\n",
    "\n",
    "df_encoded = df.copy()\n",
    "\n",
    "# Identify categorical columns\n",
    "categorical_cols = df_encoded.select_dtypes(include=['object']).columns.tolist()\n",
    "categorical_cols.remove('Churn')  # Keep target separate\n",
    "\n",
    "print(f'Categorical columns to encode: {len(categorical_cols)}')\n",
    "\n",
    "# Use Label Encoding for each categorical column\n",
    "label_encoders = {}\n",
    "for col in categorical_cols:\n",
    "    le = LabelEncoder()\n",
    "    df_encoded[col] = le.fit_transform(df_encoded[col])\n",
    "    label_encoders[col] = le\n",
    "\n",
    "# Encode target variable\n",
    "df_encoded['Churn'] = (df_encoded['Churn'] == 'Yes').astype(int)\n",
    "\n",
    "print('\\nâœ… Encoding complete!')\n",
    "df_encoded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split features and target\n",
    "X = df_encoded.drop('Churn', axis=1)\n",
    "y = df_encoded['Churn']\n",
    "\n",
    "print(f'Features shape: {X.shape}')\n",
    "print(f'Target shape: {y.shape}')\n",
    "print(f'\\nClass distribution before SMOTE:')\n",
    "print(y.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "\n",
    "print('Class distribution AFTER SMOTE:')\n",
    "print(pd.Series(y_resampled).value_counts())\n",
    "\n",
    "print('\\nğŸ’¡ Now both classes have equal samples!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the change\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# Before SMOTE\n",
    "y.value_counts().plot(kind='bar', ax=axes[0], color=['#2ecc71', '#e74c3c'])\n",
    "axes[0].set_title('Before SMOTE', fontweight='bold')\n",
    "axes[0].set_xlabel('Churn (0=No, 1=Yes)')\n",
    "axes[0].set_ylabel('Count')\n",
    "axes[0].set_xticklabels(['No (0)', 'Yes (1)'], rotation=0)\n",
    "\n",
    "# After SMOTE\n",
    "pd.Series(y_resampled).value_counts().plot(kind='bar', ax=axes[1], color=['#2ecc71', '#e74c3c'])\n",
    "axes[1].set_title('After SMOTE', fontweight='bold')\n",
    "axes[1].set_xlabel('Churn (0=No, 1=Yes)')\n",
    "axes[1].set_ylabel('Count')\n",
    "axes[1].set_xticklabels(['No (0)', 'Yes (1)'], rotation=0)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 5: Model Training and Evaluation\n",
    "\n",
    "We will train two models:\n",
    "1. **Logistic Regression** - Simple, interpretable baseline\n",
    "2. **Random Forest** - Tree-based ensemble method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-Test Split (use resampled data)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_resampled, y_resampled, test_size=0.2, random_state=42, stratify=y_resampled\n",
    ")\n",
    "\n",
    "print(f'Training set: {X_train.shape[0]} samples')\n",
    "print(f'Test set: {X_test.shape[0]} samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale features (important for Logistic Regression)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print('âœ… Features scaled!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1: Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Logistic Regression\n",
    "lr_model = LogisticRegression(random_state=42, max_iter=1000)\n",
    "lr_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred_lr = lr_model.predict(X_test_scaled)\n",
    "y_prob_lr = lr_model.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "print('âœ… Logistic Regression trained!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Logistic Regression\n",
    "print('ğŸ“Š Logistic Regression Results:')\n",
    "print('=' * 50)\n",
    "print(f'Accuracy:  {accuracy_score(y_test, y_pred_lr):.4f}')\n",
    "print(f'Precision: {precision_score(y_test, y_pred_lr):.4f}')\n",
    "print(f'Recall:    {recall_score(y_test, y_pred_lr):.4f}')\n",
    "print(f'F1-Score:  {f1_score(y_test, y_pred_lr):.4f}')\n",
    "print(f'ROC-AUC:   {roc_auc_score(y_test, y_prob_lr):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2: Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Random Forest\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "rf_model.fit(X_train, y_train)  # Random Forest doesn't need scaling\n",
    "\n",
    "# Predictions\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "y_prob_rf = rf_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print('âœ… Random Forest trained!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Random Forest\n",
    "print('ğŸ“Š Random Forest Results:')\n",
    "print('=' * 50)\n",
    "print(f'Accuracy:  {accuracy_score(y_test, y_pred_rf):.4f}')\n",
    "print(f'Precision: {precision_score(y_test, y_pred_rf):.4f}')\n",
    "print(f'Recall:    {recall_score(y_test, y_pred_rf):.4f}')\n",
    "print(f'F1-Score:  {f1_score(y_test, y_pred_rf):.4f}')\n",
    "print(f'ROC-AUC:   {roc_auc_score(y_test, y_prob_rf):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare models\n",
    "print('ğŸ“Š Model Comparison:')\n",
    "print('=' * 60)\n",
    "metrics = ['Accuracy', 'Precision', 'Recall', 'F1-Score', 'ROC-AUC']\n",
    "lr_scores = [\n",
    "    accuracy_score(y_test, y_pred_lr),\n",
    "    precision_score(y_test, y_pred_lr),\n",
    "    recall_score(y_test, y_pred_lr),\n",
    "    f1_score(y_test, y_pred_lr),\n",
    "    roc_auc_score(y_test, y_prob_lr)\n",
    "]\n",
    "rf_scores = [\n",
    "    accuracy_score(y_test, y_pred_rf),\n",
    "    precision_score(y_test, y_pred_rf),\n",
    "    recall_score(y_test, y_pred_rf),\n",
    "    f1_score(y_test, y_pred_rf),\n",
    "    roc_auc_score(y_test, y_prob_rf)\n",
    "]\n",
    "\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Metric': metrics,\n",
    "    'Logistic Regression': lr_scores,\n",
    "    'Random Forest': rf_scores\n",
    "})\n",
    "comparison_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-validation to get more reliable estimates\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Logistic Regression CV\n",
    "lr_cv_scores = cross_val_score(lr_model, X_train_scaled, y_train, cv=cv, scoring='roc_auc')\n",
    "print(f'Logistic Regression CV ROC-AUC: {lr_cv_scores.mean():.4f} (+/- {lr_cv_scores.std():.4f})')\n",
    "\n",
    "# Random Forest CV\n",
    "rf_cv_scores = cross_val_score(rf_model, X_train, y_train, cv=cv, scoring='roc_auc')\n",
    "print(f'Random Forest CV ROC-AUC: {rf_cv_scores.mean():.4f} (+/- {rf_cv_scores.std():.4f})')\n",
    "\n",
    "print('\\nğŸ’¡ Cross-validation helps us understand how stable our model performance is.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 6: Decision-Based Threshold Analysis\n",
    "\n",
    "**Default threshold = 0.5**: If probability > 0.5, predict churn.\n",
    "\n",
    "**But wait!** Different errors have different costs:\n",
    "- **False Negative (FN)**: Customer will churn, we predict they won't â†’ HIGH COST (lost customer)\n",
    "- **False Positive (FP)**: Customer won't churn, we predict they will â†’ LOW COST (unnecessary discount)\n",
    "\n",
    "Let's test different thresholds to minimize total business cost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define business costs\n",
    "COST_FN = 500  # Cost of losing a customer (lost revenue)\n",
    "COST_FP = 50   # Cost of giving unnecessary discount\n",
    "\n",
    "print('ğŸ’° Business Cost Assumptions:')\n",
    "print(f'   â€¢ False Negative (missed churner): ${COST_FN}')\n",
    "print(f'   â€¢ False Positive (unnecessary offer): ${COST_FP}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test different thresholds\n",
    "thresholds = [0.3, 0.4, 0.5, 0.6]\n",
    "\n",
    "# Use Random Forest probabilities (or Logistic Regression)\n",
    "probabilities = y_prob_rf  # Using RF model\n",
    "\n",
    "results = []\n",
    "\n",
    "for thresh in thresholds:\n",
    "    # Make predictions based on threshold\n",
    "    y_pred_thresh = (probabilities >= thresh).astype(int)\n",
    "    \n",
    "    # Calculate confusion matrix\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred_thresh).ravel()\n",
    "    \n",
    "    # Calculate total cost\n",
    "    total_cost = (fn * COST_FN) + (fp * COST_FP)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    \n",
    "    results.append({\n",
    "        'Threshold': thresh,\n",
    "        'True Positives': tp,\n",
    "        'False Positives': fp,\n",
    "        'True Negatives': tn,\n",
    "        'False Negatives': fn,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'Total Cost ($)': total_cost\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "print('ğŸ“Š Threshold Analysis Results:')\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the optimal threshold\n",
    "optimal_idx = results_df['Total Cost ($)'].idxmin()\n",
    "optimal_threshold = results_df.loc[optimal_idx, 'Threshold']\n",
    "\n",
    "print(f'âœ… OPTIMAL THRESHOLD: {optimal_threshold}')\n",
    "print(f'   This threshold minimizes total business cost to ${results_df.loc[optimal_idx, \"Total Cost ($)\"]:,.0f}')\n",
    "\n",
    "print('\\nğŸ’¡ WHY NOT 0.5?')\n",
    "print('   Because missing a churner costs more than giving an unnecessary discount.')\n",
    "print('   A lower threshold catches more churners (higher recall) at the cost of more false alarms.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize threshold analysis\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# Total Cost by Threshold\n",
    "axes[0].bar(results_df['Threshold'].astype(str), results_df['Total Cost ($)'], \n",
    "            color=['#2ecc71' if t == optimal_threshold else '#3498db' for t in results_df['Threshold']])\n",
    "axes[0].set_title('Total Business Cost by Threshold', fontweight='bold')\n",
    "axes[0].set_xlabel('Threshold')\n",
    "axes[0].set_ylabel('Total Cost ($)')\n",
    "\n",
    "# Recall by Threshold\n",
    "axes[1].plot(results_df['Threshold'], results_df['Recall'], 'o-', color='#e74c3c', linewidth=2, markersize=10)\n",
    "axes[1].set_title('Recall (Churner Detection Rate) by Threshold', fontweight='bold')\n",
    "axes[1].set_xlabel('Threshold')\n",
    "axes[1].set_ylabel('Recall')\n",
    "axes[1].axvline(x=optimal_threshold, color='green', linestyle='--', label=f'Optimal: {optimal_threshold}')\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 7: Error Analysis\n",
    "\n",
    "Let's understand WHERE our model makes mistakes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use optimal threshold for final predictions\n",
    "y_pred_final = (y_prob_rf >= optimal_threshold).astype(int)\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred_final)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=['Predicted: No', 'Predicted: Yes'],\n",
    "            yticklabels=['Actual: No', 'Actual: Yes'])\n",
    "plt.title(f'Confusion Matrix (Threshold = {optimal_threshold})', fontweight='bold')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()\n",
    "\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "print(f'\\nğŸ“Š Confusion Matrix Breakdown:')\n",
    "print(f'   â€¢ True Negatives (correctly predicted NO churn): {tn}')\n",
    "print(f'   â€¢ True Positives (correctly predicted churn): {tp}')\n",
    "print(f'   â€¢ False Positives (wrongly predicted churn): {fp}')\n",
    "print(f'   â€¢ False Negatives (missed churners): {fn}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze misclassified cases\n",
    "# Create a dataframe with predictions\n",
    "test_analysis = X_test.copy()\n",
    "test_analysis['Actual'] = y_test.values\n",
    "test_analysis['Predicted'] = y_pred_final\n",
    "test_analysis['Probability'] = y_prob_rf\n",
    "\n",
    "# False Negatives (Missed Churners) - Most costly errors\n",
    "false_negatives = test_analysis[(test_analysis['Actual'] == 1) & (test_analysis['Predicted'] == 0)]\n",
    "\n",
    "# False Positives (Unnecessary offers)\n",
    "false_positives = test_analysis[(test_analysis['Actual'] == 0) & (test_analysis['Predicted'] == 1)]\n",
    "\n",
    "print(f'ğŸ“Š Error Analysis:')\n",
    "print(f'   â€¢ False Negatives (missed churners): {len(false_negatives)}')\n",
    "print(f'   â€¢ False Positives (false alarms): {len(false_positives)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare characteristics of False Negatives vs True Positives\n",
    "true_positives = test_analysis[(test_analysis['Actual'] == 1) & (test_analysis['Predicted'] == 1)]\n",
    "\n",
    "print('ğŸ“Š Characteristics of Missed Churners (False Negatives):')\n",
    "print('\\nMedian values:')\n",
    "print(f\"   Tenure: {false_negatives['tenure'].median():.1f} months\")\n",
    "print(f\"   Monthly Charges: ${false_negatives['MonthlyCharges'].median():.2f}\")\n",
    "\n",
    "print('\\nğŸ“Š Characteristics of Correctly Predicted Churners (True Positives):')\n",
    "print('\\nMedian values:')\n",
    "print(f\"   Tenure: {true_positives['tenure'].median():.1f} months\")\n",
    "print(f\"   Monthly Charges: ${true_positives['MonthlyCharges'].median():.2f}\")\n",
    "\n",
    "print('\\nğŸ’¡ INSIGHT: Missed churners might have different characteristics than typical churners.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## ğŸ“ Final Summary and Business Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('=' * 70)\n",
    "print('                    PROJECT SUMMARY')\n",
    "print('=' * 70)\n",
    "\n",
    "print('\\nğŸ“Š DATASET:')\n",
    "print(f'   â€¢ {len(df):,} customers analyzed')\n",
    "print(f'   â€¢ Churn rate: ~27%')\n",
    "\n",
    "print('\\nğŸ” KEY FINDINGS FROM EDA:')\n",
    "print('   â€¢ New customers (< 12 months) are most likely to churn')\n",
    "print('   â€¢ Month-to-month contracts have 43% churn rate')\n",
    "print('   â€¢ Fiber optic customers have highest churn')\n",
    "\n",
    "print('\\nğŸ¤– MODEL PERFORMANCE:')\n",
    "print(f'   â€¢ Best model: Random Forest')\n",
    "print(f'   â€¢ ROC-AUC: {roc_auc_score(y_test, y_prob_rf):.4f}')\n",
    "print(f'   â€¢ Optimal threshold: {optimal_threshold}')\n",
    "\n",
    "print('\\nğŸ’¼ BUSINESS RECOMMENDATIONS:')\n",
    "print('   1. Focus retention efforts on customers in first 12 months')\n",
    "print('   2. Incentivize customers to sign longer contracts')\n",
    "print('   3. Investigate fiber optic service quality issues')\n",
    "print('   4. Use the model to identify high-risk customers proactively')\n",
    "\n",
    "print('\\n' + '=' * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ‰ Project Complete!\n",
    "\n",
    "This notebook covers the complete end-to-end Customer Churn Risk Modeling process:\n",
    "\n",
    "1. âœ… Data Loading and Understanding\n",
    "2. âœ… Data Cleaning and Preprocessing\n",
    "3. âœ… Exploratory Data Analysis\n",
    "4. âœ… Class Imbalance Handling (SMOTE)\n",
    "5. âœ… Model Training (Logistic Regression + Random Forest)\n",
    "6. âœ… Decision-Based Threshold Analysis\n",
    "7. âœ… Error Analysis\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
